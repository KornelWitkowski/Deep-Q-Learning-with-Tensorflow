{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl74xjUIqgzrJqtnJmWhpg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KornelWitkowski/Deep-Q-Learning-with-Tensorflow/blob/main/Packman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cart Pole"
      ],
      "metadata": {
        "id": "khDAbORTlGbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "l09JYBb6WZcu",
        "outputId": "72b30733-e192-462c-f6bb-2d1b69ffa15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is interrupted.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "apt-get install swig\n",
        "\n",
        "git clone https://github.com/pybox2d/pybox2d\n",
        "cd pybox2d\n",
        "python setup.py build\n",
        "python setup.py install\n",
        "\n",
        "apt-get install -y xvfb\n",
        "\n",
        "pip install \\\n",
        "    pyglet==1.5.27 \\\n",
        "    pyvirtualdisplay\n",
        "\n",
        "pip install --upgrade gym==0.19.0\n",
        "pip install gym[atari,accept-rom-license]==0.19.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display(visible=False, size=(1400, 900)).start();"
      ],
      "metadata": {
        "id": "EgZFl9-9WrLC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "class DeepQLearningModel:\n",
        "  def __init__(self, observation_size, hidden_size, action_size, learning_rate=0.001):\n",
        "\n",
        "    self.model = Sequential([Flatten(),\n",
        "                             Dense(hidden_size, activation=\"relu\"),\n",
        "                             Dense(hidden_size, activation=\"relu\"),\n",
        "                             Dense(action_size)])\n",
        "    self.compile()\n",
        "    \n",
        "  def compile(self, learning_rate=0.001):  \n",
        "    self.model.compile(loss=\"mse\",\n",
        "                       optimizer=Adam(learning_rate=learning_rate))\n",
        "    \n",
        "  def fit(self, x, y):\n",
        "    history = self.model.fit(x, y, epochs=1, verbose=0)\n",
        "    loss =  history.history[\"loss\"][0]\n",
        "    return loss"
      ],
      "metadata": {
        "id": "rGqiApB_W-oR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def epsilon_greedy_policy(state, environment, model, epsilon=0.0):\n",
        "\n",
        "  if np.random.random() < epsilon:\n",
        "    action = random.choice([0, 1])\n",
        "  else:\n",
        "    q_values = model(tf.expand_dims(state, axis=0))\n",
        "    action = tf.math.argmax(q_values, axis=1)\n",
        "    action = int(action)\n",
        "  return action"
      ],
      "metadata": {
        "id": "Dmfo4yJtXCXH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class ReplayBuffer:\n",
        "\n",
        "  def __init__(self, capacity):\n",
        "    self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def append(self, experience):\n",
        "    self.buffer.append(experience)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    return random.sample(self.buffer, batch_size)"
      ],
      "metadata": {
        "id": "72NjdgUpXUVZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, TimeLimit\n",
        "\n",
        "def create_gym_environment(name):\n",
        "  environment = gym.make(name)\n",
        "  environment = TimeLimit(environment, max_episode_steps=800)\n",
        "  environment = RecordVideo(environment, video_folder='./recored_episodes', episode_trigger=lambda x: x % 50 == 0)\n",
        "  environment = RecordEpisodeStatistics(environment)\n",
        "\n",
        "  return environment"
      ],
      "metadata": {
        "id": "Mutb5WDxXmBX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gym==0.21.0"
      ],
      "metadata": {
        "id": "OYdvyDwtMJhS",
        "outputId": "25ce4fa5-2129-460b-cb7e-6adea59b6184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym==0.21.0 in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.21.0) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.21.0) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym[atari,accept-rom-license]==0.21.0"
      ],
      "metadata": {
        "id": "rcE6E2kGMVPp",
        "outputId": "da8abf51-9b28-49d1-f61e-f784ae154dc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari]==0.21.0 in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (1.21.6)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (0.4.2)\n",
            "Requirement already satisfied: ale-py~=0.7.1 in /usr/local/lib/python3.8/dist-packages (from gym[accept-rom-license,atari]==0.21.0) (0.7.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.1->gym[accept-rom-license,atari]==0.21.0) (5.1.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.1->gym[accept-rom-license,atari]==0.21.0) (5.10.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2.23.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.8/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (0.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->ale-py~=0.7.1->gym[accept-rom-license,atari]==0.21.0) (3.11.0)\n",
            "Requirement already satisfied: libtorrent in /usr/local/lib/python3.8/dist-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]==0.21.0) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "P44iUEacMZ74"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym[atari]"
      ],
      "metadata": {
        "id": "dP0uZyjOOoNT",
        "outputId": "a62c28cb-4475-48b2-b069-fcaf2d833458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (1.21.6)\n",
            "Requirement already satisfied: ale-py~=0.7.1 in /usr/local/lib/python3.8/dist-packages (from gym[atari]) (0.7.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.1->gym[atari]) (5.1.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py~=0.7.1->gym[atari]) (5.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->ale-py~=0.7.1->gym[atari]) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall ale-py"
      ],
      "metadata": {
        "id": "8Uo1MWFBOp57",
        "outputId": "80182c75-96c4-48d1-f993-c4e3ca5dcf01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: ale-py 0.7.5\n",
            "Uninstalling ale-py-0.7.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/ale-import-roms\n",
            "    /usr/local/lib/python3.8/dist-packages/ale_py-0.7.5.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/ale_py/*\n",
            "    /usr/local/lib/python3.8/dist-packages/gym/envs/atari/*\n",
            "Proceed (y/n)? Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/uninstall.py\", line 85, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/req/req_install.py\", line 658, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/req/req_uninstall.py\", line 380, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/req/req_uninstall.py\", line 423, in _allowed_to_proceed\n",
            "    return ask('Proceed (y/n)? ', ('y', 'n')) == 'y'\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/misc.py\", line 203, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1493, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1577, in _log\n",
            "    fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ale-py"
      ],
      "metadata": {
        "id": "addzAC-1OsAU",
        "outputId": "9f95a3b5-4d32-4d8d-e1cb-f3eee52dafba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.8/dist-packages (0.7.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from ale-py) (5.1.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from ale-py) (5.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ale-py) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->ale-py) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "Gz97UgjFO11H"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"MsPacman-v0\")"
      ],
      "metadata": {
        "id": "m1AsQZDMjW0R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gym.make(\"ALE/Phoenix-v5\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mW1iJxk_OSuY",
        "outputId": "0c5efccb-5583-4e84-afa6-7bfae1df6690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OrderEnforcing<AtariEnv<ALE/Phoenix-v5>>>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTut1RyKjaoE",
        "outputId": "b9c33f40-e18b-49d9-e05a-7cc8f8947d02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        ...,\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111]],\n",
              "\n",
              "       [[228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        ...,\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111],\n",
              "        [228, 111, 111]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(2)"
      ],
      "metadata": {
        "id": "gqDbD-ICQMak",
        "outputId": "ea3b5ee3-ddf6-402a-cafc-78637a4a7e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         ...,\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111]],\n",
              " \n",
              "        [[228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         ...,\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8),\n",
              " 0.0,\n",
              " False,\n",
              " {'lives': 3, 'episode_frame_number': 4, 'frame_number': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = create_gym_environment(\"MsPacman-v0\")"
      ],
      "metadata": {
        "id": "w35XDLlBUcDH",
        "outputId": "f3cfd9d2-28fa-45c3-b6b1-81f86eda6320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/recored_episodes folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = env.action_space.sample()\n",
        "x"
      ],
      "metadata": {
        "id": "ASZlQ6EwUETH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "metadata": {
        "id": "nS-j14MBXZjv",
        "outputId": "0e3b7dfb-f453-4184-d4d8-ac69d00f34a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(9)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "id": "m-ub8Bg9UVWL",
        "outputId": "18e7489b-620c-4c1d-9b6f-2631830dbcdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         ...,\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111]],\n",
              " \n",
              "        [[228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         ...,\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111],\n",
              "         [228, 111, 111]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]],\n",
              " \n",
              "        [[  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         ...,\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0],\n",
              "         [  0,   0,   0]]], dtype=uint8),\n",
              " {'lives': 3, 'episode_frame_number': 0, 'frame_number': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ns, r, d, i = env.step(1)\n"
      ],
      "metadata": {
        "id": "iFlLKzheXBbC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_state, reward, done, info = env.step(x)\n",
        "next_state, reward, done, info"
      ],
      "metadata": {
        "id": "TFs5BCAq2FK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_state[1]"
      ],
      "metadata": {
        "id": "l7EXcBkz2QAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(range(5))"
      ],
      "metadata": {
        "id": "WsBY4YG_YmX0",
        "outputId": "b6c208d7-b52b-4e0c-d53a-5d9e8748c5fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, TimeLimit\n",
        "\n",
        "import gym\n",
        "\n",
        "class DeepQLearningAlgorithm:\n",
        "\n",
        "    def __init__(self, environment_name=\"MsPacman-v0\", policy=epsilon_greedy_policy, capacity=100_000,\n",
        "                batch_size=256, learning_rate=1e-3, hidden_size=128, gamma=0.99, epsilon_start=1.0, epsilon_end=0.15,\n",
        "                epsilon_last_episode=600, samples_per_epoch=2_048//8, q_net_update_rate=10):\n",
        "    \n",
        "      self.environment = create_gym_environment(environment_name)\n",
        "      observation_size = self.environment.observation_space.shape[0]\n",
        "      actions_size = self.environment.action_space.n\n",
        "\n",
        "      self.q_net = DeepQLearningModel(observation_size, hidden_size, actions_size, learning_rate)\n",
        "      self.target_q_net = copy.deepcopy(self.q_net.model)\n",
        "\n",
        "      self.policy = policy\n",
        "      self.buffer = ReplayBuffer(capacity=capacity)\n",
        "\n",
        "       \n",
        "      self.current_epoch = 0\n",
        "      self.total_reward = 0\n",
        "\n",
        "\n",
        "      # hyperparameters\n",
        "      self.batch_size = batch_size\n",
        "      self.learning_rate = learning_rate\n",
        "      self.gamma = 0.99\n",
        "      self.epsilon_start = epsilon_start\n",
        "      self.epsilon_end = epsilon_end\n",
        "      self.epsilon_last_episode = epsilon_last_episode\n",
        "      self.samples_per_epoch = samples_per_epoch\n",
        "      self.q_net_update_rate = 10\n",
        "\n",
        "\n",
        "      while len(self.buffer) < self.samples_per_epoch:\n",
        "        self.play_episode(epsilon=0)\n",
        "        \n",
        "    def play_episode(self, policy=None, epsilon=0.):\n",
        "      state = self.environment.reset()\n",
        "      done = False\n",
        "      self.total_reward = 0\n",
        "\n",
        "      while not done:\n",
        "        if policy:\n",
        "          action = policy(state, self.environment, self.q_net.model, epsilon=epsilon)\n",
        "        else:\n",
        "          action = random.choice(range(self.environment.action_space.n))\n",
        "\n",
        "        next_state, reward, done, info = self.environment.step(action)\n",
        "        self.total_reward += reward\n",
        "\n",
        "        # reward = (10 * next_state[1])**2\n",
        "\n",
        "        # if next_state[0] >= 0.45:\n",
        "        #   reward += 100\n",
        "        # self.total_reward += reward\n",
        "\n",
        "\n",
        "        exp = (state, action, reward, done, next_state)\n",
        "        self.buffer.append(exp)\n",
        "        state = next_state\n",
        "\n",
        "      return\n",
        "\n",
        "    def get_batch(self):\n",
        "      sample = pd.DataFrame(self.buffer.sample(self.batch_size))\n",
        "\n",
        "      state = np.stack(sample[0].values)\n",
        "      action = np.stack(sample[1].values)\n",
        "      reward = np.stack(sample[2].values)\n",
        "      done = np.stack(sample[3].values)\n",
        "      next_state = np.stack(sample[4].values)\n",
        "\n",
        "      return state, action, reward, done, next_state\n",
        "\n",
        "\n",
        "    def train_step(self):\n",
        "      states, actions, rewards, dones, next_states = self.get_batch()\n",
        "\n",
        "      state_action_values = tf.gather(self.q_net.model(states), actions, axis=1, batch_dims=1)\n",
        "\n",
        "\n",
        "      next_action_values = tf.math.reduce_max(self.target_q_net(next_states), axis=1)\n",
        "\n",
        "      next_action_values = next_action_values.numpy()\n",
        "      next_action_values[dones] = 0.0\n",
        "\n",
        "      expected_state_action_values = rewards + self.gamma * next_action_values\n",
        "\n",
        "      q_net_predictions = self.q_net.model(states).numpy()\n",
        "      q_net_predictions[range(self.batch_size), actions] = expected_state_action_values\n",
        "\n",
        "      loss = self.q_net.fit(states, q_net_predictions)\n",
        "\n",
        "      return loss\n",
        "\n",
        "      \n",
        "    def training_epoch_end(self):\n",
        "\n",
        "        epsilon = max(self.epsilon_end,\n",
        "                      self.epsilon_start - self.current_epoch / self.epsilon_last_episode)\n",
        "\n",
        "        self.play_episode(policy=self.policy, epsilon=epsilon)\n",
        "\n",
        "        if self.current_epoch % self.q_net_update_rate == 0:\n",
        "          self.target_q_net = copy.deepcopy(self.q_net.model)\n",
        "          \n",
        "\n",
        "        return\n",
        "        \n",
        "    def train(self, epochs):\n",
        "\n",
        "      for i in range(epochs):\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for _ in range(self.samples_per_epoch//self.batch_size):  \n",
        "          loss += self.train_step()\n",
        "\n",
        "        self.training_epoch_end()\n",
        "\n",
        "        if self.current_epoch % 50 == 0:\n",
        "          returns = list(self.environment.return_queue)[-1]\n",
        "          print(f\"Epoch: {self.current_epoch}, loss: {loss}, last total reward: {self.total_reward}\")\n",
        "\n",
        "        self.current_epoch += 1\n"
      ],
      "metadata": {
        "id": "lKNohAHCXy-x"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/recored_episodes\n",
        "\n",
        "algorithm =  DeepQLearningAlgorithm(hidden_size=256)"
      ],
      "metadata": {
        "id": "hJJeHlaDYIgx"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm.train(2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_VeU674YOeR",
        "outputId": "2a6373c5-a3b5-4f11-ec14-07369159692b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 7732325.5, last total reward: 120.0\n",
            "Epoch: 50, loss: 10873.4521484375, last total reward: 90.0\n",
            "Epoch: 100, loss: 3135.95654296875, last total reward: 120.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJ3NyjG8PyOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}